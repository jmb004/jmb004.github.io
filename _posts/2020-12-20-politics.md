---
layout: post
title: 'Producing a helper-script for political election 2020 in Python'
published: true
---
# Myth-Busting #
Can you write a code that will help you pick a political candidate? I say "yes!".

The main points of the Python script were to create a way to come up with an election choice much faster with web-scrapping and keyword searching based on user input. It is assumed that we are working with candidates in my political district in the 2020 election. 

# Scraping for Politicians #
The goal here is to get all the data on the candidates from scraping 1 webpage from their website. The idea was to get the computer to do the hardwork of researching the candidates rather than reading the websites myself. The first script is to scrape the web for the candidates from the Michigan election in my voting district. Then when the websites are in HTML within text files, the user is given the open to move over to the keyword search script. The result of the web-scrape is the folder shown below with all the HTML labeled.
(Note the references for script structures in the comments of the code.)
[see script](https://github.com/jmb004/jmb004.github.io/blob/master/_posts/keyword_ranking.py)

![Folder](/images/Capture.PNG)

# Keyword Search #
Then the keyword search program is run. [see script](https://github.com/jmb004/jmb004.github.io/blob/master/_posts/keyword_ranking.py) It looks at all the HTML text and searches for a keyword from the user's input. The goal here is to get the lines of the website that relate to the issues that I care enough to search for. The other part, is that the code generates what website the returned matched lines are from, this way I know what candidate I am reading about. 

# Lessons learned #
Looking back on this project, it seems that I could have devloped the code in two directions: first, either scrape the entire website (nested pages and all) or set-up some kind of parameters to scrape only those pages which I knew or assumed had information that I wanted.

It speeds up the process of deciding a little bit, since I narrowed down my reading and research to a few dozen lines. 

The other part is that the keyword search needs to be expanded to multiple searches or keywords per search, so that it can return the most valuable information right away and not through multiple searches. I had some ideas to work out the project into a another script where the keywords could be ranked by order of interest and then the results of where those keywords are along with the corresponding lines from the HTML could be counted and given in a summary form (statistics) for each website. So, for example, if I'm interested in three issues: Guns, Abortion, and Marriage, I can search those terms and then the return from the function would be a list of the keywords and the candidatess websites (or names) where the results were found and the number of lines where those keywords show up. (i.e, Guns: Donald Trump: 27...). 
Or, the results of the keyword search could be put into order in the printing thus ranking them out of the gate. 

In short, while there are lots of creative ways to make it easier to decide on a candidate, one way is to use your coding knowledge and web-scraping to get the help you need.

# Appendix #

Code for keyword searching.

    #!python3

    """
    import modules
    """
    import logging, glob, googlesearch, random, tempfile, shutil, sys, nltk, fake_useragent, wordcloud, bs4, selenium, pandas, numpy, os, selenium, openpyxl, requests, re, time, urllib.request, cert_human, pycparser, cffi, cryptography, OpenSSL, asn1crypto, certifi, ssl
    from os import path
    from itertools import cycle


    """
    # set os
    """
    cd = os.getcwd()

    """
    search downloaded HTML now text files for keyword in a sentence and return the sentence with the website
    """

    def keyword_search(pattern):
        pattern = re.compile(pattern)
        p = str(pattern)

        files = glob.glob("www.*.txt")

        for file in files:
            for line in open(file, encoding="utf8"):
                line = line.strip().lower()
                for match in re.finditer(pattern, line): # return an iterator of the pattern keyword and the line from the html
                    try:
                        print("Found", p[12:-2], "in" , file, "here:", line) # Found (key-pattern-word) in (www.joebalog.com) here: (Joe belives in key-pattern-word).
                    except:
                        raise Exception


    # take user input
    pattern = input("What is a keyword you want to search the websites for? i.e., guns") # i.e., guns

    keyword_search(pattern) # run keyword search through html


